{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Required Libraries\n",
    "    pandas (pd): Used for data manipulation and analysis.\n",
    "    numpy (np): Supports numerical computations.\n",
    "    matplotlib.pyplot (plt): Used for data visualization.\n",
    "    seaborn (sns): Provides advanced statistical plotting.\n",
    "    \n",
    "    sklearn.preprocessing:\n",
    "       LabelEncoder: Converts categorical values into numerical codes.\n",
    "       StandardScaler: Standardizes numerical features (mean=0, std=1).\n",
    "       MinMaxScaler: Scales numerical values to a fixed range (0 to 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2. Load the Dataset\n",
    "    Reads the dataset from the specified file path and loads it into a pandas DataFrame (df).\n",
    "    This step ensures we can analyze and manipulate the data in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Dataset\n",
    "df = pd.read_csv(\"../data/Customer Purchasing Behaviors.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3. Check General Information   \n",
    "    ✅df.info(): Displays the column names, data types, non-null values, and memory usage.\n",
    "                 Helps in detecting missing values and identifying categorical vs. numerical columns.\n",
    "    ✅df.head(): Prints the first five rows to get an overview of the dataset.\n",
    "                 Helps check if the dataset loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 238 entries, 0 to 237\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   user_id             238 non-null    int64  \n",
      " 1   age                 238 non-null    int64  \n",
      " 2   annual_income       238 non-null    int64  \n",
      " 3   purchase_amount     238 non-null    int64  \n",
      " 4   loyalty_score       238 non-null    float64\n",
      " 5   region              238 non-null    object \n",
      " 6   purchase_frequency  238 non-null    int64  \n",
      "dtypes: float64(1), int64(5), object(1)\n",
      "memory usage: 13.1+ KB\n",
      "None\n",
      "   user_id  age  annual_income  purchase_amount  loyalty_score region  \\\n",
      "0        1   25          45000              200            4.5  North   \n",
      "1        2   34          55000              350            7.0  South   \n",
      "2        3   45          65000              500            8.0   West   \n",
      "3        4   22          30000              150            3.0   East   \n",
      "4        5   29          47000              220            4.8  North   \n",
      "\n",
      "   purchase_frequency  \n",
      "0                  12  \n",
      "1                  18  \n",
      "2                  22  \n",
      "3                  10  \n",
      "4                  13  \n"
     ]
    }
   ],
   "source": [
    "#Check General Information\n",
    "print(df.info())  # Get column types and missing values\n",
    "print(df.head())  # Display first few rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generate Summary Statistics\n",
    "Provides descriptive statistics for numerical columns:\n",
    "\n",
    "✅Count (number of non-null values).<br>\n",
    "✅Mean, Std (Standard Deviation).<br>\n",
    "✅Min, Max, 25th, 50th, 75th percentiles (Quartiles).<br>\n",
    "    \n",
    "    Helps identify outliers, data ranges, and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          user_id         age  annual_income  purchase_amount  loyalty_score  \\\n",
      "count  238.000000  238.000000     238.000000       238.000000     238.000000   \n",
      "mean   119.500000   38.676471   57407.563025       425.630252       6.794118   \n",
      "std     68.848868    9.351118   11403.875717       140.052062       1.899047   \n",
      "min      1.000000   22.000000   30000.000000       150.000000       3.000000   \n",
      "25%     60.250000   31.000000   50000.000000       320.000000       5.500000   \n",
      "50%    119.500000   39.000000   59000.000000       440.000000       7.000000   \n",
      "75%    178.750000   46.750000   66750.000000       527.500000       8.275000   \n",
      "max    238.000000   55.000000   75000.000000       640.000000       9.500000   \n",
      "\n",
      "       purchase_frequency  \n",
      "count          238.000000  \n",
      "mean            19.798319  \n",
      "std              4.562884  \n",
      "min             10.000000  \n",
      "25%             17.000000  \n",
      "50%             20.000000  \n",
      "75%             23.000000  \n",
      "max             28.000000  \n"
     ]
    }
   ],
   "source": [
    "#summary statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Check Unique Values in Categorical Columns\n",
    "    df.select_dtypes(include=[\"object\"]) filters only categorical columns.\n",
    ".nunique() counts the number of unique values in each categorical column.\n",
    "    \n",
    "    This helps:\n",
    "    ✅Identify categorical variables for encoding.\n",
    "    ✅Detect high-cardinality columns (columns with too many unique values).\n",
    "    ✅Spot potential errors, such as inconsistent formatting in categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region: 4 unique values\n"
     ]
    }
   ],
   "source": [
    "#Check Unique Values in Categorical Columns\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    print(f\"{col}: {df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "    This initial data cleaning and exploration process helps us understand the structure of the dataset, detect missing values, identify categorical variables, and assess numerical distributions. By performing these steps, we can determine necessary preprocessing actions such as handling missing data, encoding categorical features, and scaling numerical values before building a predictive model.\n",
    "\n",
    "    Moving forward, we can refine the dataset by addressing data inconsistencies, outliers, and feature transformations to ensure a high-quality input for our regression analysis on customer loyalty scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
